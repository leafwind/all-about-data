# Data Pipeline Design Rules & Check List

#### 

---

# Rules

## Rule \#1 做好 data pruning 的準備 / 培養 data fetch cost 的概念

沒有做過 data pipeline 的工程師，在做一個服務的時候

很自然會想要把資料先全部蒐集起來，然後再慢慢處理邏輯

但這麼做很常是不切實際的

的確，機器成本越來越低，很多技術也都已經 scalable，但技術上做得到，不代表預算做得到

所以常會面臨到無法處理完所有資料的情形


把 fetch cost 最低的資料先拿到，不需要的支線砍掉，fetch cost 最高的擺在最後處理

通常可以只用到原本的 10% 甚至 1% 機器



舉例來說，假設手上有一年的資料，但遠超出可以負荷的時間與預算

那麼如果時效性重要的，可以考慮只留下最近一個月的資料即可

或者想要分析 CTR，那麼只要留下使用者看過的 log 即可

或是一一調整客戶的案子，那麼只要拿目前還有在跑的案子即可

這些看似簡單，但若不知道資料的意義，卻很容易被忽略

## Rule #2 培養找尋備案（fallback plan）的能力

如果是在一間組織分工明確、需求被清楚定義的公司

那可能可以假設需要的資料一定隨時都能拿到，所有服務也都很難會有 downtime

但大部分公司都不是如此（至少台灣不是）

有時候是系統不穩定、自己寫的程式不穩定

有時候是外部來的資料不穩定

再有時候是成長快速、需求變動頻繁，即使系統沒有出狀況，也很容易不敷使用

因此

需要 A 資料，但原本抓取一次回應時間只要 1s，現在變成 10s 怎麼辦

需要 B 資料，但有 10% 的機會拿不到要 retry，甚至無法同步拿到，只能改用非同步

# Check Lists

## Data Generation（不只是生資料，還要問怎麼生）

* Freshness(Delay)

  * 上游拿到資料時已經延遲多久？
  * 下游可以接受資料延遲多久才拿到？
  * 從發生行為到客戶看到資料要多久以內？
  
* Frequency

  * 上游多久更新一次？
  * 下游可以接受多久更新一次？
  
👉客戶可以接受多久更新一次，需要多新的資料？
有些後端分析給公司內部使用，可能只要一天一次，也不用當天就要看得到資料，這種需求就比較好設計，成本也相對低
有些情況比較偏重後者，比如客戶需要至少今天晚上看得到早上的資料
有些則更極端，比如異常狀況偵測的 log 五分鐘內就要能反應在演算法上，否則線上服務會有嚴重影響
通常 update frequency 的需求，增加機器就可以解決，但若對資料的「新鮮度」有比較嚴格的要求，可能就要改變設計，甚至砍掉重練，重做一條特製化的 ETL
有價值的需求值得為它打造一條路，但量身訂做也就代表開發、維護成本都比較高

* Timing

  * 什麼時間 cluster 比較忙？
  * 什麼時間上游還沒生出來不用白跑？

* Trigger

  * 需要有人通知他開跑嗎？
  * 上游有辦法通知他嗎？
  * 網路能通嗎？

### 舊資料的要求

* Retention Policy

👉太舊的資料要怎麼淘汰？
現在 storage 不管在哪都算是相對便宜的成本
如果是只牽涉到儲存成本的情況
比如像 s3，只要有設定好 retention policy，通常不用太斤斤計較。
但仍然有一些情況不太好處理
例如設計不良的 MySQL，經年累月發現 table 跟 index 都已經非常肥
這時候「砍資料」本身可能就是一件麻煩事
要砍資料或是更改 schema 可能就要採取比較迂迴的作法

* Backfill Support

  * 會需要以前的資料嗎？
  * 如果要，從多久以前開始？
  
👉如果需要以前某段時間的資料，有沒有辦法只更新那一部分？
上面講的是多了要砍
有時候發現過去某段時間的資料來源裡面有垃圾，或資料的定義在個時間點之後偷偷改變了，但又不想重跑全部
這些少了要補的情況該怎麼辦？
ETL job 有沒有辦法彈性地指定時間去更新資料？
更新完有沒有辦法無痛地放到資料庫或 ETL pipeline 當中？insert 是否要考慮 key 的問題、效率好嗎？會不會影響線上服務？

有些儲存媒介的限制與設計並沒有辦法很輕鬆地 backfill
另外一些一開始就設計不良的情況，最慘就是全部重跑



## Connectivity（上下游需求有問清楚嗎？）

上游更新頻率、delay，何時開始跑才不會炸
下游需求的更新頻率、需求 delay，如何通知他

#### 工具：

airflow dag, jenkins trigger/polling


## Pipeline Healthy (Monitor/Alert)

在重要的環節加入 log 是很合理而且直觀的

理論上 Airflow, Prometheus 可以幫助做到這件事情

但礙於時間限制，有時候不可能在所有資料生成的時候都這樣做
（e.g. 有些 ETL 在資料庫裡面查詢做轉換、有些甚至在應用程式邏輯裡面偷偷做轉換）

因此常常是爆炸之後一路循線上去查才發現某個地方有問題

有哪些常見需要記錄的問題？

data discrepancy

> 少了幾筆

schema error
> 完全不合規範的非法資料

data inconsistency

> 不那麼嚴重但是邏輯上有瑕疵的問題

performance / expected time

> 生太慢、沒有在預期時間內產出

## Data Storage

#### SQL

* Index

  * explain query first
  * Index 有順序的概念，Query 是否有按照順序（i.e. 1 or 1+2 or 1+2+3）？

* Partition

  * 單張 table 太大時要切 partition 嗎？
  * 自動 event 定時增加 partition 還是手動？AWS RDS 怎麼設定？
  * partition size?
  * partition key?
  * 如果原本沒有 partition 要怎麼 migrate table?



